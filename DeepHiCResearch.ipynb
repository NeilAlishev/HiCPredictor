{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nNotes\\n\\nв пределах 10мб - не мусорные контакты\\nвсю Hi-C карту предсказывать не надо. участки вдоль диагонали\\n\\nудалить главную диагональ? - схлопывать\\n\\n\\nTODO: реализовать RMSE и R^2 для численной оценки качества предсказаний моделей\\nРазделить на 80 training, 10 dev, 10 test\\nПосмотреть качество предсказаний на test set'е\\n\\n\\nTODO: \\nLearn only on upper triangle (2 times less output values, should be faster). \\nThen, after prediction, form 2d matrix from upper triangle\\n\\nTODO:\\nUse all chromosomes (not only one) for training and testing NN\\n\\n\\nTODO:\\nTo reduce overfitting and increase generalization\\nstochastically shift input sequences by up to +/- 11 bp and reverse complement the DNA and flip the Hi-C map.\\n(described in Fudenberg)\\n\\n\\nRefactoring is needed!\\n\\n\""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Notes\n",
    "\n",
    "в пределах 10мб - не мусорные контакты\n",
    "всю Hi-C карту предсказывать не надо. участки вдоль диагонали\n",
    "\n",
    "удалить главную диагональ? - схлопывать\n",
    "\n",
    "\n",
    "TODO: реализовать RMSE и R^2 для численной оценки качества предсказаний моделей\n",
    "Разделить на 80 training, 10 dev, 10 test\n",
    "Посмотреть качество предсказаний на test set'е\n",
    "\n",
    "\n",
    "TODO: \n",
    "Learn only on upper triangle (2 times less output values, should be faster). \n",
    "Then, after prediction, form 2d matrix from upper triangle\n",
    "\n",
    "TODO:\n",
    "Use all chromosomes (not only one) for training and testing NN\n",
    "\n",
    "\n",
    "TODO:\n",
    "To reduce overfitting and increase generalization\n",
    "stochastically shift input sequences by up to +/- 11 bp and reverse complement the DNA and flip the Hi-C map.\n",
    "(described in Fudenberg)\n",
    "\n",
    "\n",
    "Refactoring is needed!\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "pandas.set_option('display.max_columns', 500)\n",
    "pandas.set_option('display.max_rows', 500)\n",
    "\n",
    "import h5py\n",
    "import random\n",
    "\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import cooler\n",
    "import cooltools as ct\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "import pickle\n",
    "\n",
    "import scipy\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following directive activates inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# allow to allocate resources for model training\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import set_session\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "# Training set formation\n",
    "WINDOW_SIZE = 526\n",
    "STRIDE = 526 // 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTIL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hic(matrix, use_log_scale = False):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    if use_log_scale:\n",
    "        im = ax.matshow(np.log10(matrix), cmap='YlOrRd')\n",
    "        fig.colorbar(im)\n",
    "    else:\n",
    "        im = ax.matshow(matrix, cmap='YlOrRd')\n",
    "        fig.colorbar(im)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_dna(sequences = {}):\n",
    "    for k,v in sequences.items():\n",
    "        seq_array = np.array(list(v))\n",
    "\n",
    "        label_encoder = LabelEncoder()\n",
    "        integer_encoded_seq = label_encoder.fit_transform(seq_array)\n",
    "\n",
    "        integer_encoded_seq = integer_encoded_seq.reshape(len(integer_encoded_seq), 1)\n",
    "\n",
    "        onehot_encoder = OneHotEncoder(sparse = False)\n",
    "        result = onehot_encoder.fit_transform(integer_encoded_seq)\n",
    "        \n",
    "        # if Ns are present in the DNA sequence, result will have 5 columns. We delete 4th column which has Ns\n",
    "        # N row in the resulting training set will have all 0s\n",
    "        if result.shape[1] == 5:\n",
    "            result = np.delete(result, 3, 1)\n",
    "        \n",
    "        sequences[k] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_training_squares(hic_library, chroms):\n",
    "    training_set = {}\n",
    "\n",
    "    for chrom in chroms:\n",
    "        current_chrom = hic_library[chrom]\n",
    "        training_set[chrom] = []\n",
    "        \n",
    "        for part_number in sorted(current_chrom.keys()):\n",
    "            current_chrom_part = current_chrom[part_number]\n",
    "            \n",
    "            for i in range(WINDOW_SIZE, current_chrom_part.shape[0], STRIDE):\n",
    "                training_set[chrom].append((current_chrom_part[i - WINDOW_SIZE:i, i - WINDOW_SIZE:i],\n",
    "                                          (i - WINDOW_SIZE, i)))\n",
    "            \n",
    "    return training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_train_x(sequences_one_hot, chroms, training_squares):\n",
    "    train_x = []\n",
    "    \n",
    "    for chrom in chroms:\n",
    "        cur_seq = sequences_one_hot[chrom]\n",
    "        cur_training_squares = training_squares[chrom]\n",
    "\n",
    "        for training_square in cur_training_squares:\n",
    "            sq_begin, sq_end = training_square[1]\n",
    "            train_x.append(cur_seq[(sq_begin * 1000):(sq_end * 1000), ])\n",
    "\n",
    "            \n",
    "    return np.asarray(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_train_y(training_squares, chroms):\n",
    "    train_y = []\n",
    "    \n",
    "    for chrom in chroms:            \n",
    "        cur_training_squares = training_squares[chrom]\n",
    "\n",
    "        for training_square in cur_training_squares:\n",
    "            CROPPING_TARGET = 7\n",
    "            cropped_training_square = training_square[0][CROPPING_TARGET:training_square[0].shape[0] - CROPPING_TARGET, \n",
    "                                                         CROPPING_TARGET:training_square[0].shape[1] - CROPPING_TARGET]\n",
    "\n",
    "            upper_triu = to_upper_triu(cropped_training_square, diagonal_offset=2)\n",
    "            train_y.append(upper_triu)\n",
    "            \n",
    "            \n",
    "    return np.asarray(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_upper_triu(input_matrix, diagonal_offset = 2):\n",
    "    seq_len = input_matrix.shape[0]\n",
    "    return input_matrix[np.triu_indices(seq_len, diagonal_offset)].reshape([-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab specific code\n",
    "# filepath = \"drive/My Drive/Colab Notebooks/S2-Wang2017-async.dm3.mapq_30.100.mcool\"\n",
    "\n",
    "filepath = \"S2-Wang2017-async.dm3.mapq_30.100.mcool\"\n",
    "\n",
    "resolution = \"::/resolutions/1000\" # 1 KB resolution\n",
    "c = cooler.Cooler(filepath + resolution)\n",
    "\n",
    "chroms = c.chromnames\n",
    "# don't use these small chromosomes\n",
    "chroms.remove(\"chrM\")\n",
    "chroms.remove(\"chr4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T RUN: Transform all chromosome Hi-C maps and write them to file\n",
    "for chrom in chroms:\n",
    "    arr = c.matrix(balance=True).fetch(chrom)\n",
    "    # For adaptive coarse-grain transformation purposes\n",
    "    arr_raw = c.matrix(balance=False).fetch(chrom)\n",
    "    \n",
    "    transformed_arr = transform_hic(arr, arr_raw)\n",
    "    file_name = chrom + \"_transformed.npy\"\n",
    "    np.save(f\"./transformed_hic/{file_name}\", transformed_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hic(arr, use_log_scale = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all transformed Hi-C\n",
    "transformed_hic = {}\n",
    "for chrom in chroms:\n",
    "    chrom_hic_filenames = [filename for filename in os.listdir('./transformed_hic') if filename.startswith(chrom)]\n",
    "    \n",
    "    if len(chrom_hic_filenames) > 0:\n",
    "        chrom_parts = {}\n",
    "        for filename in chrom_hic_filenames:\n",
    "            current_part_number = int(re.search(\"(transformed)(\\d+)\", filename).group(2))\n",
    "            chrom_parts[current_part_number] = np.load(f\"./transformed_hic/{filename}\")['arr_0']\n",
    "\n",
    "        transformed_hic[chrom] = chrom_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_squares = select_training_squares(transformed_hic, chroms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = {}\n",
    "for chrom in chroms:\n",
    "    fasta_sequence = list(SeqIO.parse(open(f\"./chromFa/{chrom}.fa\"),'fasta'))[0]\n",
    "    sequences[chrom] = str(fasta_sequence.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Воспринимаю маленькие и большие буквы одинаковым образом (??? Это норм ???)\n",
    "for k in sequences.keys():\n",
    "    sequences[k] = sequences[k].upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neil/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/neil/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/neil/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/neil/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Users/neil/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Преобразую последовательности в one-hot encoding (A = 0, C = 1, G = 2, T = 3)\n",
    "one_hot_dna(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = form_train_x(sequences, chroms, training_squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = form_train_y(training_squares, chroms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(731, 526000, 4)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(731, 130305, 1)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop train_x to match 524288\n",
    "CROPPING_FACTOR_DNA = 856\n",
    "cropped_train_x = []\n",
    "for i in range(train_x.shape[0]):\n",
    "    cur_seq = train_x[i, :, :]\n",
    "    cropped_train_x.append(cur_seq[CROPPING_FACTOR_DNA: cur_seq.shape[0] - CROPPING_FACTOR_DNA, :])\n",
    "    \n",
    "cropped_train_x = np.asarray(cropped_train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = cropped_train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"./train_x.npz\", train_x)\n",
    "np.savez_compressed(\"./train_y.npz\", train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.load(\"./train_x.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convnet model (similar to Fudenberg NN):\n",
    "\n",
    "model_m = Sequential()\n",
    "\n",
    "model_m.add(layers.Conv1D(25, 50, activation='relu', input_shape=(50000, 4)))\n",
    "model_m.add(layers.Conv1D(25, 50, activation='relu'))\n",
    "model_m.add(layers.MaxPooling1D(5, strides = 2))\n",
    "\n",
    "model_m.add(layers.Conv1D(50, 25, activation='relu'))\n",
    "model_m.add(layers.MaxPooling1D(5, strides = 2))\n",
    "\n",
    "model_m.add(layers.Conv1D(50, 25, activation='relu'))\n",
    "model_m.add(layers.MaxPooling1D(20, strides = 4))\n",
    "\n",
    "model_m.add(layers.Conv1D(70, 20, activation='relu'))\n",
    "model_m.add(layers.MaxPooling1D(25, strides = 4))\n",
    "\n",
    "# dilated layers\n",
    "model_m.add(layers.Conv1D(100, 15, activation='relu', dilation_rate = 2))\n",
    "model_m.add(layers.Conv1D(100, 15, activation='relu', dilation_rate = 2))\n",
    "model_m.add(layers.MaxPooling1D(25, strides = 4))\n",
    "\n",
    "model_m.add(layers.Flatten())\n",
    "model_m.add(layers.Dense(2500, activation='linear'))\n",
    "\n",
    "# здесь можно не использовать входы (50 штук) и схлопывать после предсказания НС\n",
    "# не 2.500, а 2.450\n",
    "# для тренировки и для предсказаний надо будет сначала делать трансформацию для вектора\n",
    "\n",
    "print(model_m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_m.compile(optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
    "              loss='mse',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_m.fit(train_x,\n",
    "                      train_y,\n",
    "                      batch_size=32,\n",
    "                      epochs=3,\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_m.load_weights('project2_model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hic(training_squares[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_begin, sq_end = training_squares[0][1]\n",
    "seq_to_use = current_seq_one_hot[(sq_begin * 1000):(sq_end * 1000), ].reshape((1,50000, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_m.predict(seq_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hic(prediction.reshape((50, 50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_m.load_weights('project2_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hic(training_squares[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_begin, sq_end = training_squares[3][1]\n",
    "seq_to_use = current_seq_one_hot[(sq_begin * 1000):(sq_end * 1000), ].reshape((1,50000, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_m.predict(seq_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hic(prediction.reshape((50, 50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fudenberg избавляется от scaling'а\n",
    "# избавиться от шкалирования. полимерное свойство хроматина нам не обязательно выучивать\n",
    "# Нам надо это делать:\n",
    "# observed/expected - Саша отправит\n",
    "# можно применять observed/expected для всей хромосомы или для каждого квардрата 50x50\n",
    "# для каждого квардрата делать observed/expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Басет работа - 2015 (размеры слоев и параметры оттуда)\n",
    "# В басет предсказывается DNA sequence -> accessibility (open versus closed chromatin) of this area \n",
    "# (in different cell types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convnet model (similar to Basset NN):\n",
    "# Basset NN is not trainable in a reasonable time with this 50x50 window size -> reduced to 25x25 window size\n",
    "# Nevertheless, 3 times more tunable parameters than Fudenberg\n",
    "\n",
    "model_m = Sequential()\n",
    "\n",
    "model_m.add(layers.Conv1D(300, 21, activation='relu', input_shape=(25000, 4)))\n",
    "model_m.add(layers.MaxPooling1D(4))\n",
    "\n",
    "model_m.add(layers.Conv1D(300, 6, activation='relu'))\n",
    "model_m.add(layers.MaxPooling1D(4))\n",
    "\n",
    "model_m.add(layers.Conv1D(500, 4, activation='relu'))\n",
    "model_m.add(layers.MaxPooling1D(4))\n",
    "\n",
    "model_m.add(layers.Flatten())\n",
    "\n",
    "model_m.add(layers.Dense(1000, activation='relu'))\n",
    "\n",
    "model_m.add(layers.Dense(625, activation='linear'))\n",
    "\n",
    "print(model_m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_m.load_weights('project2_model_Basset.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hic(training_squares[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_begin, sq_end = training_squares[3][1]\n",
    "seq_to_use = current_seq_one_hot[(sq_begin * 1000):(sq_end * 1000), ].reshape((1,25000, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_m.predict(seq_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hic(prediction.reshape((25, 25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hi-C tranformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hic(arr[0:1000, 0:1000], use_log_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Adaptive coarse-grain\n",
    "transformed_arr = ct.lib.numutils.adaptive_coarsegrain(arr[0:1000, 0:1000], arr_raw[0:1000, 0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hic(transformed_arr, use_log_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Normalize the contact matrix for distance-dependent contact decay.\n",
    "# Observed/Expected\n",
    "transformed_arr, _, _, _ = ct.lib.numutils.observed_over_expected(transformed_arr, mask = ~np.isnan(transformed_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hic(transformed_arr, use_log_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Take natural logarithm\n",
    "transformed_arr = np.log(transformed_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hic(transformed_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Interpolate all NaN values\n",
    "transformed_arr = ct.lib.numutils.interp_nan(transformed_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hic(transformed_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Use Gaussian filter\n",
    "# To get rid of noise, emphasizing larger patterns.\n",
    "transformed_arr = scipy.ndimage.gaussian_filter(transformed_arr, sigma = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hic(transformed_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all the transformations in one function\n",
    "def transform_hic(hic_matrix, hic_matrix_raw):\n",
    "    transformed_arr = ct.lib.numutils.adaptive_coarsegrain(hic_matrix, hic_matrix_raw)\n",
    "    transformed_arr, _, _, _ = ct.lib.numutils.observed_over_expected(transformed_arr, mask = ~np.isnan(transformed_arr))\n",
    "    transformed_arr = np.log(transformed_arr)\n",
    "    transformed_arr = ct.lib.numutils.interp_nan(transformed_arr)\n",
    "    transformed_arr = scipy.ndimage.gaussian_filter(transformed_arr, sigma = 1)\n",
    "    \n",
    "    return transformed_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hic(arr[0:4000, 0:4000], use_log_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hic(transform_hic(arr[2500:3000, 2500:3000], arr_raw[2500:3000, 2500:3000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: RMSE and R^2. split on train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (None, 5, 3) -> (None, 5, 5, 3)\n",
    "# Explanation of the 1D -> 2D procedure\n",
    "\n",
    "oned = tf.constant([[[1, 6, 11], \n",
    "                     [2, 7, 12], \n",
    "                     [3, 8, 13],\n",
    "                     [4, 9, 14],\n",
    "                     [5, 10, 15]],\n",
    "                   \n",
    "                    [[1, 6, 11], \n",
    "                     [2, 7, 12], \n",
    "                     [3, 8, 13],\n",
    "                     [4, 9, 14],\n",
    "                     [5, 10, 15]],\n",
    "                   \n",
    "                    [[1, 6, 11], \n",
    "                     [2, 7, 12], \n",
    "                     [3, 8, 13],\n",
    "                     [4, 9, 14],\n",
    "                     [5, 10, 15]]])\n",
    "\n",
    "_, seq_len, features = oned.shape\n",
    "twod1 = tf.tile(oned, [1, seq_len, 1])\n",
    "twod1 = tf.reshape(twod1, [-1, seq_len, seq_len, features])\n",
    "twod2 = tf.transpose(twod1, [0,2,1,3])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(\"Original tiled tensor for one 1D filter (1D filter expanded 5 times)\")\n",
    "    print(np.array(sess.run([twod1]))[0][0][:, :, 0])\n",
    "    \n",
    "    print(\"Transposed tiled tensor\")\n",
    "    print(np.array(sess.run([twod2]))[0][0][:, :, 0])\n",
    "\n",
    "\n",
    "twod1 = tf.expand_dims(twod1, axis=-1)\n",
    "twod2 = tf.expand_dims(twod2, axis=-1)\n",
    "twod  = tf.concat([twod1, twod2], axis=-1)\n",
    "twod = tf.reduce_mean(twod, axis=-1)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(\"Result of mean operation between original and transposed (mean between each pair of values in 1D filter)\")\n",
    "    print(np.array(sess.run([twod]))[0][0][:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exlanation of ConcatDist2D procedure\n",
    "# This layer adds one more channel which contains pairwise distances for the matrices obtained on the previous layer\n",
    "# (this should enhance model performance)\n",
    "# (None, 5, 5, 3) -> (None, 5, 5, 4)\n",
    "\n",
    "# For one training example -> (1,5,5,3)\n",
    "inputs = tf.random.uniform(shape=[1,5,5,3])\n",
    "\n",
    "input_shape = tf.shape(inputs)\n",
    "batch_size, seq_len = input_shape[0], input_shape[1]\n",
    "\n",
    "## concat 2D distance ##\n",
    "pos = tf.expand_dims(tf.range(0, seq_len), axis=-1)\n",
    "matrix_repr1 = tf.tile(pos, [1,seq_len])\n",
    "matrix_repr2 = tf.transpose(matrix_repr1, [1,0])\n",
    "dist  = tf.math.abs( tf.math.subtract(matrix_repr1, matrix_repr2) )\n",
    "dist = tf.dtypes.cast(dist, tf.float32)\n",
    "dist = tf.expand_dims(dist, axis=-1)\n",
    "dist = tf.expand_dims(dist, axis=0)\n",
    "dist = tf.tile(dist, [batch_size, 1, 1, 1])\n",
    "\n",
    "res = tf.concat([inputs, dist], axis=-1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(np.array(sess.run([res]))[0, :, :, :, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Custom Keras layers\n",
    "###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneToTwo(tf.keras.layers.Layer):\n",
    "    ''' Transform 1d to 2d with i,j vectors operated on.'''\n",
    "    def __init__(self, operation='mean'):\n",
    "        super(OneToTwo, self).__init__()\n",
    "\n",
    "    def call(self, oned):\n",
    "        _, seq_len, features = oned.shape\n",
    "\n",
    "        twod1 = tf.tile(oned, [1, seq_len, 1])\n",
    "        twod1 = tf.reshape(twod1, [-1, seq_len, seq_len, features])\n",
    "        twod2 = tf.transpose(twod1, [0,2,1,3])\n",
    "\n",
    "        twod1 = tf.expand_dims(twod1, axis=-1)\n",
    "        twod2 = tf.expand_dims(twod2, axis=-1)\n",
    "        twod  = tf.concat([twod1, twod2], axis=-1)\n",
    "        twod = tf.reduce_mean(twod, axis=-1)\n",
    "\n",
    "        return twod\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config['operation'] = self.operation\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatDist2D(tf.keras.layers.Layer):\n",
    "    ''' Concatenate the pairwise distance to 2d feature matrix.'''\n",
    "    def __init__(self):\n",
    "        super(ConcatDist2D, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, seq_len = input_shape[0], input_shape[1]\n",
    "\n",
    "        ## concat 2D distance ##\n",
    "        pos = tf.expand_dims(tf.range(0, seq_len), axis=-1)\n",
    "        matrix_repr1 = tf.tile(pos, [1, seq_len])\n",
    "        matrix_repr2 = tf.transpose(matrix_repr1, [1, 0])\n",
    "        dist = tf.math.abs(tf.math.subtract(matrix_repr1, matrix_repr2))\n",
    "        dist = tf.dtypes.cast(dist, tf.float32)\n",
    "        dist = tf.expand_dims(dist, axis=-1)\n",
    "        dist = tf.expand_dims(dist, axis=0)\n",
    "        dist = tf.tile(dist, [batch_size, 1, 1, 1])\n",
    "        return tf.concat([inputs, dist], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Symmetrize2D(tf.keras.layers.Layer):\n",
    "    '''Take the average of a matrix and its transpose to enforce symmetry.'''\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Symmetrize2D, self).__init__()\n",
    "\n",
    "    def call(self, x):\n",
    "        x_t = tf.transpose(x, [0, 2, 1, 3])\n",
    "        x_sym = (x + x_t) / 2\n",
    "        return x_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpperTri(tf.keras.layers.Layer):\n",
    "    ''' Unroll matrix to its upper triangular portion.'''\n",
    "\n",
    "    def __init__(self, diagonal_offset=2):\n",
    "        super(UpperTri, self).__init__()\n",
    "        self.diagonal_offset = diagonal_offset\n",
    "\n",
    "    def call(self, inputs):\n",
    "        seq_len = inputs.shape[1].value\n",
    "        output_dim = inputs.shape[-1]\n",
    "\n",
    "        triu_tup = np.triu_indices(seq_len, self.diagonal_offset)\n",
    "        triu_index = list(triu_tup[0] + seq_len * triu_tup[1])\n",
    "        unroll_repr = tf.reshape(inputs, [-1, seq_len ** 2, output_dim])\n",
    "        return tf.gather(unroll_repr, triu_index, axis=1)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config['diagonal_offset'] = self.diagonal_offset\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticReverseComplement(tf.keras.layers.Layer):\n",
    "    \"\"\"Stochastically reverse complement a one hot encoded DNA sequence.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(StochasticReverseComplement, self).__init__()\n",
    "\n",
    "    def call(self, seq_1hot, training=None):\n",
    "        if training:\n",
    "            rc_seq_1hot = tf.gather(seq_1hot, [3, 2, 1, 0], axis=-1)\n",
    "            rc_seq_1hot = tf.reverse(rc_seq_1hot, axis=[1])\n",
    "            reverse_bool = tf.random.uniform(shape=[]) > 0.5\n",
    "            src_seq_1hot = tf.cond(reverse_bool, lambda: rc_seq_1hot, lambda: seq_1hot)\n",
    "            return src_seq_1hot, reverse_bool\n",
    "        else:\n",
    "            return seq_1hot, tf.constant(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticShift(tf.keras.layers.Layer):\n",
    "    \"\"\"Stochastically shift a one hot encoded DNA sequence.\"\"\"\n",
    "\n",
    "    def __init__(self, shift_max=0, pad='uniform'):\n",
    "        super(StochasticShift, self).__init__()\n",
    "        self.shift_max = shift_max\n",
    "        self.augment_shifts = tf.range(-self.shift_max, self.shift_max + 1)\n",
    "        self.pad = pad\n",
    "\n",
    "    def call(self, seq_1hot, training=None):\n",
    "        if training:\n",
    "            shift_i = tf.random.uniform(shape=[], minval=0, dtype=tf.int64,\n",
    "                                        maxval=len(self.augment_shifts))\n",
    "            shift = tf.gather(self.augment_shifts, shift_i)\n",
    "            sseq_1hot = tf.cond(tf.not_equal(shift, 0),\n",
    "                                lambda: shift_sequence(seq_1hot, shift),\n",
    "                                lambda: seq_1hot)\n",
    "            return sseq_1hot\n",
    "        else:\n",
    "            return seq_1hot\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'shift_max': self.shift_max,\n",
    "            'pad': self.pad\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "def shift_sequence(seq, shift, pad_value=0.25):\n",
    "    \"\"\"Shift a sequence left or right by shift_amount.\n",
    "    Args:\n",
    "    seq: [batch_size, seq_length, seq_depth] sequence\n",
    "    shift: signed shift value (tf.int32 or int)\n",
    "    pad_value: value to fill the padding (primitive or scalar tf.Tensor)\n",
    "    \"\"\"\n",
    "    if seq.shape.ndims != 3:\n",
    "        raise ValueError('input sequence should be rank 3')\n",
    "    input_shape = seq.shape\n",
    "\n",
    "    pad = pad_value * tf.ones_like(seq[:, 0:tf.abs(shift), :])\n",
    "\n",
    "    def _shift_right(_seq):\n",
    "        # shift is positive\n",
    "        sliced_seq = _seq[:, :-shift:, :]\n",
    "        return tf.concat([pad, sliced_seq], axis=1)\n",
    "\n",
    "    def _shift_left(_seq):\n",
    "        # shift is negative\n",
    "        sliced_seq = _seq[:, -shift:, :]\n",
    "        return tf.concat([sliced_seq, pad], axis=1)\n",
    "\n",
    "    sseq = tf.cond(tf.greater(shift, 0),\n",
    "                   lambda: _shift_right(seq),\n",
    "                   lambda: _shift_left(seq))\n",
    "    sseq.set_shape(input_shape)\n",
    "\n",
    "    return sseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwitchReverse(tf.keras.layers.Layer):\n",
    "    \"\"\"Reverse predictions if the inputs were reverse complemented.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SwitchReverse, self).__init__()\n",
    "\n",
    "    def call(self, x_reverse):\n",
    "        x = x_reverse[0]\n",
    "        reverse = x_reverse[1]\n",
    "\n",
    "        xd = len(x.shape)\n",
    "        if xd == 3:\n",
    "            rev_axes = [1]\n",
    "        elif xd == 4:\n",
    "            rev_axes = [1, 2]\n",
    "        else:\n",
    "            raise ValueError('Cannot recognize SwitchReverse input dimensions %d.' % xd)\n",
    "\n",
    "        return tf.keras.backend.switch(reverse,\n",
    "                                       tf.reverse(x, axis=rev_axes),\n",
    "                                       x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Helper functions\n",
    "###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate(current, activation, verbose=False):\n",
    "    if verbose: \n",
    "        print('activate:',activation)\n",
    "    \n",
    "    if activation == 'relu':\n",
    "        current = tf.keras.layers.ReLU()(current)\n",
    "    elif activation == 'gelu':\n",
    "        current = GELU()(current)\n",
    "    elif activation == 'sigmoid':\n",
    "        current = tf.keras.layers.Activation('sigmoid')(current)\n",
    "    elif activation == 'tanh':\n",
    "        current = tf.keras.layers.Activation('tanh')(current)\n",
    "    elif activation == 'exp':\n",
    "        current = Exp()(current)\n",
    "    elif activation == 'softplus':\n",
    "        current = Softplus()(current)\n",
    "    else:\n",
    "        print('Unrecognized activation \"%s\"' % activation, file=sys.stderr)\n",
    "        exit(1)\n",
    "\n",
    "    return current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# Keras blocks\n",
    "###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, filters=None, kernel_size=1, activation='relu', strides=1,\n",
    "    dilation_rate=1, l2_scale=0, dropout=0, conv_type='standard', residual=False,\n",
    "    pool_size=1, batch_norm=False, bn_momentum=0.99, bn_gamma=None,\n",
    "    kernel_initializer='he_normal'):\n",
    "  \n",
    "    \"\"\"Construct a single convolution block.\n",
    "    Args:\n",
    "    inputs:        [batch_size, seq_length, features] input sequence\n",
    "    filters:       Conv1D filters\n",
    "    kernel_size:   Conv1D kernel_size\n",
    "    activation:    relu/gelu/etc\n",
    "    strides:       Conv1D strides\n",
    "    dilation_rate: Conv1D dilation rate\n",
    "    l2_scale:      L2 regularization weight.\n",
    "    dropout:       Dropout rate probability\n",
    "    conv_type:     Conv1D layer type\n",
    "    residual:      Residual connection boolean\n",
    "    pool_size:     Max pool width\n",
    "    batch_norm:    Apply batch normalization\n",
    "    bn_momentum:   BatchNorm momentum\n",
    "    bn_gamma:      BatchNorm gamma (defaults according to residual)\n",
    "    Returns:\n",
    "    [batch_size, seq_length, features] output sequence\n",
    "    \"\"\"\n",
    "\n",
    "    # flow through variable current\n",
    "    current = inputs\n",
    "\n",
    "    # choose convolution type\n",
    "    if conv_type == 'separable':\n",
    "        conv_layer = tf.keras.layers.SeparableConv1D\n",
    "    else:\n",
    "        conv_layer = tf.keras.layers.Conv1D\n",
    "\n",
    "    if filters is None:\n",
    "        filters = inputs.shape[-1]\n",
    "\n",
    "    # activation\n",
    "    current = activate(current, activation)\n",
    "\n",
    "    # convolution\n",
    "    current = conv_layer(\n",
    "        filters=filters,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides,\n",
    "        padding='same',\n",
    "        use_bias=False,\n",
    "        dilation_rate=dilation_rate,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(l2_scale))(current)\n",
    "\n",
    "    # batch norm\n",
    "    if batch_norm:\n",
    "        if bn_gamma is None:\n",
    "            bn_gamma = 'zeros' if residual else 'ones'\n",
    "        \n",
    "        current = tf.keras.layers.BatchNormalization(momentum=bn_momentum, gamma_initializer=bn_gamma, fused=True)(current)\n",
    "\n",
    "    # dropout\n",
    "    if dropout > 0:\n",
    "        current = tf.keras.layers.Dropout(rate=dropout)(current)\n",
    "\n",
    "    # residual add\n",
    "    if residual:\n",
    "        current = tf.keras.layers.Add()([inputs,current])\n",
    "\n",
    "    # Pool\n",
    "    if pool_size > 1:\n",
    "        current = tf.keras.layers.MaxPool1D(pool_size=pool_size, padding='same')(current)\n",
    "\n",
    "    return current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_tower(inputs, filters_init, filters_mult=1, repeat=1, **kwargs):\n",
    "    \"\"\"Construct a reducing convolution block.\n",
    "    Args:\n",
    "    inputs:        [batch_size, seq_length, features] input sequence\n",
    "    filters_init:  Initial Conv1D filters\n",
    "    filters_mult:  Multiplier for Conv1D filters\n",
    "    repeat:        Conv block repetitions\n",
    "    Returns:\n",
    "    [batch_size, seq_length, features] output sequence\n",
    "    \"\"\"\n",
    "\n",
    "    # flow through variable current\n",
    "    current = inputs\n",
    "\n",
    "    # initialize filters\n",
    "    rep_filters = filters_init\n",
    "\n",
    "    for ri in range(repeat):\n",
    "        # convolution\n",
    "        current = conv_block(current, filters=int(np.round(rep_filters)), **kwargs)\n",
    "\n",
    "    # update filters\n",
    "    rep_filters *= filters_mult\n",
    "\n",
    "    return current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilated_residual(inputs, filters, kernel_size=3, rate_mult=2, conv_type='standard', \n",
    "                     dropout=0, repeat=1, round=False, **kwargs):\n",
    "    \"\"\"Construct a residual dilated convolution block.\n",
    "    Args:\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "\n",
    "    # flow through variable current\n",
    "    current = inputs\n",
    "\n",
    "    # initialize dilation rate\n",
    "    dilation_rate = 1.0\n",
    "\n",
    "    for ri in range(repeat):\n",
    "        # For skip connection purpose\n",
    "        rep_input = current\n",
    "\n",
    "        # dilate\n",
    "        current = conv_block(current, filters=filters, kernel_size=kernel_size, \n",
    "                             dilation_rate=int(np.round(dilation_rate)), \n",
    "                             conv_type=conv_type, bn_gamma='ones', **kwargs)\n",
    "\n",
    "        # return\n",
    "        current = conv_block(current, filters=int(rep_input.shape[-1]), dropout=dropout, bn_gamma='zeros', **kwargs)\n",
    "\n",
    "        # residual add\n",
    "        current = tf.keras.layers.Add()([rep_input, current])\n",
    "\n",
    "        # update dilation rate\n",
    "        dilation_rate *= rate_mult\n",
    "        \n",
    "        if round:\n",
    "            dilation_rate = np.round(dilation_rate)\n",
    "\n",
    "    return current\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D related blocks\n",
    "\n",
    "def concat_dist_2d(inputs, **kwargs):\n",
    "    current = ConcatDist2D()(inputs)\n",
    "    return current\n",
    "\n",
    "def one_to_two(inputs, operation='mean', **kwargs):\n",
    "    current = OneToTwo(operation)(inputs)\n",
    "    return current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block_2d(inputs, filters=128, activation='relu', conv_type='standard',\n",
    "    kernel_size=1, strides=1, dilation_rate=1, l2_scale=0, dropout=0, pool_size=1,\n",
    "    batch_norm=False, bn_momentum=0.99, bn_gamma='ones', symmetric=False):\n",
    "\n",
    "    \"\"\"Construct a single 2D convolution block.   \"\"\"\n",
    "\n",
    "    # flow through variable current\n",
    "    current = inputs\n",
    "\n",
    "    # activation\n",
    "    current = activate(current, activation)\n",
    "\n",
    "  # choose convolution type\n",
    "    if conv_type == 'separable':\n",
    "        conv_layer = tf.keras.layers.SeparableConv2D\n",
    "    else:\n",
    "        conv_layer = tf.keras.layers.Conv2D\n",
    "\n",
    "    # convolution\n",
    "    current = conv_layer(\n",
    "        filters=filters,\n",
    "        kernel_size=kernel_size,\n",
    "        strides=strides,\n",
    "        padding='same',\n",
    "        use_bias=False,\n",
    "        dilation_rate=dilation_rate,\n",
    "        kernel_initializer='he_normal',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(l2_scale))(current)\n",
    "\n",
    "    # batch norm\n",
    "    if batch_norm:\n",
    "        current = tf.keras.layers.BatchNormalization(\n",
    "          momentum=bn_momentum,\n",
    "          gamma_initializer=bn_gamma,\n",
    "          fused=True)(current)\n",
    "\n",
    "    # dropout\n",
    "    if dropout > 0:\n",
    "        current = tf.keras.layers.Dropout(rate=dropout)(current)\n",
    "\n",
    "    # pool\n",
    "    if pool_size > 1:\n",
    "        current = tf.keras.layers.MaxPool2D(\n",
    "          pool_size=pool_size,\n",
    "          padding='same')(current)\n",
    "\n",
    "    # symmetric\n",
    "    if symmetric:\n",
    "        current = layers.Symmetrize2D()(current)\n",
    "\n",
    "    return current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetrize_2d(inputs, **kwargs):\n",
    "    return Symmetrize2D()(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilated_residual_2d(inputs, filters, kernel_size=3, rate_mult=2,\n",
    "                        dropout=0, repeat=1, symmetric=True, **kwargs):\n",
    "    \"\"\"Construct a residual dilated convolution block.\n",
    "    \"\"\"\n",
    "\n",
    "    # flow through variable current\n",
    "    current = inputs\n",
    "\n",
    "    # initialize dilation rate\n",
    "    dilation_rate = 1.0\n",
    "\n",
    "    for ri in range(repeat):\n",
    "        rep_input = current\n",
    "\n",
    "        # dilate\n",
    "        current = conv_block_2d(current,\n",
    "                                filters=filters,\n",
    "                                kernel_size=kernel_size,\n",
    "                                dilation_rate=int(np.round(dilation_rate)),\n",
    "                                bn_gamma='ones',\n",
    "                                **kwargs)\n",
    "\n",
    "        # return\n",
    "        current = conv_block_2d(current,\n",
    "                                filters=int(rep_input.shape[-1]),\n",
    "                                dropout=dropout,\n",
    "                                bn_gamma='zeros',\n",
    "                                **kwargs)\n",
    "\n",
    "        # residual add\n",
    "        current = tf.keras.layers.Add()([rep_input, current])\n",
    "\n",
    "        # enforce symmetry\n",
    "        if symmetric:\n",
    "            current = Symmetrize2D()(current)\n",
    "\n",
    "        # update dilation rate\n",
    "        dilation_rate *= rate_mult\n",
    "\n",
    "    return current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropping_2d(inputs, cropping, **kwargs):\n",
    "    current = tf.keras.layers.Cropping2D(cropping)(inputs)\n",
    "    return current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_tri(inputs, diagonal_offset=2, **kwargs):\n",
    "    current = UpperTri(diagonal_offset)(inputs)\n",
    "    return current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense(inputs, units, activation='softplus', kernel_initializer='he_normal',\n",
    "          l2_scale=0, l1_scale=0, **kwargs):\n",
    "    \n",
    "    current = tf.keras.layers.Dense(\n",
    "        units=units,\n",
    "        activation=activation,\n",
    "        use_bias=True,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        kernel_regularizer=tf.keras.regularizers.l1_l2(l1_scale, l2_scale)\n",
    "    )(inputs)\n",
    "    \n",
    "    return current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "\n",
    "# Changed for SEQ_LENGTH = 512000\n",
    "\n",
    "#SEQ_LENGTH = 512000\n",
    "SEQ_LENGTH = 1048576\n",
    "sequence = tf.keras.Input(shape=(SEQ_LENGTH, 4), name='sequence')\n",
    "\n",
    "current = sequence\n",
    "\n",
    "# Augmentation - Enable it later (after good performance on the training set)\n",
    "# current, reverse_bool = StochasticReverseComplement()(current)\n",
    "# augment_shift = 11\n",
    "# current = StochasticShift(augment_shift)(current)\n",
    "\n",
    "# TRUNK:\n",
    "\n",
    "# First 1D convolution\n",
    "current = conv_block(current, filters=96, kernel_size=11, pool_size=2, batch_norm=True, bn_momentum=0.9265,\n",
    "                     activation=\"relu\")\n",
    "\n",
    "\n",
    "# Change for repeat = 9\n",
    "\n",
    "# Multiple (11) 1D convolutions in a tower to arrive to 2048bp representation in 1D vectors\n",
    "current = conv_tower(current, filters_init=96, filters_mult=1.0, kernel_size=5, pool_size=2, repeat=9, \n",
    "                     batch_norm=True, bn_momentum=0.9265, activation=\"relu\")\n",
    "\n",
    "# Dilated residual layers\n",
    "current = dilated_residual(current, filters=48, rate_mult=1.75, repeat=8, dropout=0.4, batch_norm=True, \n",
    "                           bn_momentum=0.9265, activation=\"relu\")\n",
    "\n",
    "# Bottleneck 1D convolution\n",
    "current = conv_block(current, filters=64, kernel_size=5, batch_norm=True, bn_momentum=0.9265,\n",
    "                     activation=\"relu\")\n",
    "\n",
    "# final activation\n",
    "current = activate(current, \"relu\")\n",
    "\n",
    "\n",
    "# HEAD:\n",
    "current = one_to_two(current)\n",
    "current = concat_dist_2d(current)\n",
    "current = conv_block_2d(current, filters=48, kernel_size=3, batch_norm=True, bn_momentum=0.9265,\n",
    "                     activation=\"relu\")\n",
    "\n",
    "current = symmetrize_2d(current)\n",
    "current = dilated_residual_2d(current, filters=24, kernel_size=3, rate_mult=1.75, repeat=6, dropout=0.1,\n",
    "                              batch_norm=True, bn_momentum=0.9265, activation=\"relu\")\n",
    "\n",
    "# TODO: TRY WITHOUT CROP\n",
    "current = cropping_2d(current, cropping=26)\n",
    "\n",
    "current = upper_tri(current, diagonal_offset=2)\n",
    "\n",
    "#current = dense(current, units=1, activation=\"linear\")\n",
    "current = dense(current, units=5, activation=\"linear\")\n",
    "\n",
    "# current = SwitchReverse()([current, reverse_bool])\n",
    "\n",
    "# make model\n",
    "model = tf.keras.Model(inputs=sequence, outputs=current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sequence (InputLayer)           [(None, 1048576, 4)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_412 (ReLU)                (None, 1048576, 4)   0           sequence[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_272 (Conv1D)             (None, 1048576, 96)  4224        re_lu_412[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_402 (BatchN (None, 1048576, 96)  384         conv1d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_102 (MaxPooling1D (None, 524288, 96)   0           batch_normalization_402[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_413 (ReLU)                (None, 524288, 96)   0           max_pooling1d_102[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_273 (Conv1D)             (None, 524288, 96)   46080       re_lu_413[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_403 (BatchN (None, 524288, 96)   384         conv1d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_103 (MaxPooling1D (None, 262144, 96)   0           batch_normalization_403[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_414 (ReLU)                (None, 262144, 96)   0           max_pooling1d_103[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_274 (Conv1D)             (None, 262144, 96)   46080       re_lu_414[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_404 (BatchN (None, 262144, 96)   384         conv1d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_104 (MaxPooling1D (None, 131072, 96)   0           batch_normalization_404[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_415 (ReLU)                (None, 131072, 96)   0           max_pooling1d_104[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_275 (Conv1D)             (None, 131072, 96)   46080       re_lu_415[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_405 (BatchN (None, 131072, 96)   384         conv1d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_105 (MaxPooling1D (None, 65536, 96)    0           batch_normalization_405[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_416 (ReLU)                (None, 65536, 96)    0           max_pooling1d_105[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_276 (Conv1D)             (None, 65536, 96)    46080       re_lu_416[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_406 (BatchN (None, 65536, 96)    384         conv1d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_106 (MaxPooling1D (None, 32768, 96)    0           batch_normalization_406[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_417 (ReLU)                (None, 32768, 96)    0           max_pooling1d_106[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_277 (Conv1D)             (None, 32768, 96)    46080       re_lu_417[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_407 (BatchN (None, 32768, 96)    384         conv1d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_107 (MaxPooling1D (None, 16384, 96)    0           batch_normalization_407[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_418 (ReLU)                (None, 16384, 96)    0           max_pooling1d_107[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_278 (Conv1D)             (None, 16384, 96)    46080       re_lu_418[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_408 (BatchN (None, 16384, 96)    384         conv1d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_108 (MaxPooling1D (None, 8192, 96)     0           batch_normalization_408[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_419 (ReLU)                (None, 8192, 96)     0           max_pooling1d_108[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_279 (Conv1D)             (None, 8192, 96)     46080       re_lu_419[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_409 (BatchN (None, 8192, 96)     384         conv1d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_109 (MaxPooling1D (None, 4096, 96)     0           batch_normalization_409[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_420 (ReLU)                (None, 4096, 96)     0           max_pooling1d_109[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_280 (Conv1D)             (None, 4096, 96)     46080       re_lu_420[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_410 (BatchN (None, 4096, 96)     384         conv1d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_110 (MaxPooling1D (None, 2048, 96)     0           batch_normalization_410[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_421 (ReLU)                (None, 2048, 96)     0           max_pooling1d_110[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_281 (Conv1D)             (None, 2048, 96)     46080       re_lu_421[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_411 (BatchN (None, 2048, 96)     384         conv1d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_111 (MaxPooling1D (None, 1024, 96)     0           batch_normalization_411[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_422 (ReLU)                (None, 1024, 96)     0           max_pooling1d_111[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_282 (Conv1D)             (None, 1024, 48)     13824       re_lu_422[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_412 (BatchN (None, 1024, 48)     192         conv1d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_423 (ReLU)                (None, 1024, 48)     0           batch_normalization_412[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_283 (Conv1D)             (None, 1024, 96)     4608        re_lu_423[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_413 (BatchN (None, 1024, 96)     384         conv1d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_140 (Dropout)           (None, 1024, 96)     0           batch_normalization_413[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_140 (Add)                   (None, 1024, 96)     0           max_pooling1d_111[0][0]          \n",
      "                                                                 dropout_140[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_424 (ReLU)                (None, 1024, 96)     0           add_140[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_284 (Conv1D)             (None, None, 48)     13824       re_lu_424[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_414 (BatchN (None, None, 48)     192         conv1d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_425 (ReLU)                (None, None, 48)     0           batch_normalization_414[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_285 (Conv1D)             (None, None, 96)     4608        re_lu_425[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_415 (BatchN (None, None, 96)     384         conv1d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_141 (Dropout)           (None, None, 96)     0           batch_normalization_415[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_141 (Add)                   (None, 1024, 96)     0           add_140[0][0]                    \n",
      "                                                                 dropout_141[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_426 (ReLU)                (None, 1024, 96)     0           add_141[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_286 (Conv1D)             (None, None, 48)     13824       re_lu_426[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_416 (BatchN (None, None, 48)     192         conv1d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_427 (ReLU)                (None, None, 48)     0           batch_normalization_416[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_287 (Conv1D)             (None, None, 96)     4608        re_lu_427[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_417 (BatchN (None, None, 96)     384         conv1d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_142 (Dropout)           (None, None, 96)     0           batch_normalization_417[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_142 (Add)                   (None, 1024, 96)     0           add_141[0][0]                    \n",
      "                                                                 dropout_142[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_428 (ReLU)                (None, 1024, 96)     0           add_142[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_288 (Conv1D)             (None, None, 48)     13824       re_lu_428[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_418 (BatchN (None, None, 48)     192         conv1d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_429 (ReLU)                (None, None, 48)     0           batch_normalization_418[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_289 (Conv1D)             (None, None, 96)     4608        re_lu_429[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_419 (BatchN (None, None, 96)     384         conv1d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_143 (Dropout)           (None, None, 96)     0           batch_normalization_419[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_143 (Add)                   (None, 1024, 96)     0           add_142[0][0]                    \n",
      "                                                                 dropout_143[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_430 (ReLU)                (None, 1024, 96)     0           add_143[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_290 (Conv1D)             (None, None, 48)     13824       re_lu_430[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_420 (BatchN (None, None, 48)     192         conv1d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_431 (ReLU)                (None, None, 48)     0           batch_normalization_420[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_291 (Conv1D)             (None, None, 96)     4608        re_lu_431[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_421 (BatchN (None, None, 96)     384         conv1d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_144 (Dropout)           (None, None, 96)     0           batch_normalization_421[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_144 (Add)                   (None, 1024, 96)     0           add_143[0][0]                    \n",
      "                                                                 dropout_144[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_432 (ReLU)                (None, 1024, 96)     0           add_144[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_292 (Conv1D)             (None, None, 48)     13824       re_lu_432[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_422 (BatchN (None, None, 48)     192         conv1d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_433 (ReLU)                (None, None, 48)     0           batch_normalization_422[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_293 (Conv1D)             (None, None, 96)     4608        re_lu_433[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_423 (BatchN (None, None, 96)     384         conv1d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_145 (Dropout)           (None, None, 96)     0           batch_normalization_423[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_145 (Add)                   (None, 1024, 96)     0           add_144[0][0]                    \n",
      "                                                                 dropout_145[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_434 (ReLU)                (None, 1024, 96)     0           add_145[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_294 (Conv1D)             (None, None, 48)     13824       re_lu_434[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_424 (BatchN (None, None, 48)     192         conv1d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_435 (ReLU)                (None, None, 48)     0           batch_normalization_424[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_295 (Conv1D)             (None, None, 96)     4608        re_lu_435[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_425 (BatchN (None, None, 96)     384         conv1d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_146 (Dropout)           (None, None, 96)     0           batch_normalization_425[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_146 (Add)                   (None, 1024, 96)     0           add_145[0][0]                    \n",
      "                                                                 dropout_146[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_436 (ReLU)                (None, 1024, 96)     0           add_146[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_296 (Conv1D)             (None, None, 48)     13824       re_lu_436[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_426 (BatchN (None, None, 48)     192         conv1d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_437 (ReLU)                (None, None, 48)     0           batch_normalization_426[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_297 (Conv1D)             (None, None, 96)     4608        re_lu_437[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_427 (BatchN (None, None, 96)     384         conv1d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_147 (Dropout)           (None, None, 96)     0           batch_normalization_427[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_147 (Add)                   (None, 1024, 96)     0           add_146[0][0]                    \n",
      "                                                                 dropout_147[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_438 (ReLU)                (None, 1024, 96)     0           add_147[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_298 (Conv1D)             (None, 1024, 64)     30720       re_lu_438[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_428 (BatchN (None, 1024, 64)     256         conv1d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_439 (ReLU)                (None, 1024, 64)     0           batch_normalization_428[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "one_to_two_9 (OneToTwo)         (None, 1024, 1024, 6 0           re_lu_439[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concat_dist2d_10 (ConcatDist2D) (None, 1024, 1024, 6 0           one_to_two_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_440 (ReLU)                (None, 1024, 1024, 6 0           concat_dist2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 1024, 1024, 4 28080       re_lu_440[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_429 (BatchN (None, 1024, 1024, 4 192         conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_70 (Symmetrize2D)  (None, 1024, 1024, 4 0           batch_normalization_429[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_441 (ReLU)                (None, 1024, 1024, 4 0           symmetrize2d_70[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 1024, 1024, 2 10368       re_lu_441[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_430 (BatchN (None, 1024, 1024, 2 96          conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_442 (ReLU)                (None, 1024, 1024, 2 0           batch_normalization_430[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 1024, 1024, 4 1152        re_lu_442[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_431 (BatchN (None, 1024, 1024, 4 192         conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_148 (Dropout)           (None, 1024, 1024, 4 0           batch_normalization_431[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_148 (Add)                   (None, 1024, 1024, 4 0           symmetrize2d_70[0][0]            \n",
      "                                                                 dropout_148[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_71 (Symmetrize2D)  (None, 1024, 1024, 4 0           add_148[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_443 (ReLU)                (None, 1024, 1024, 4 0           symmetrize2d_71[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, None, None, 2 10368       re_lu_443[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_432 (BatchN (None, None, None, 2 96          conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_444 (ReLU)                (None, None, None, 2 0           batch_normalization_432[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, None, None, 4 1152        re_lu_444[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_433 (BatchN (None, None, None, 4 192         conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_149 (Dropout)           (None, None, None, 4 0           batch_normalization_433[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_149 (Add)                   (None, 1024, 1024, 4 0           symmetrize2d_71[0][0]            \n",
      "                                                                 dropout_149[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_72 (Symmetrize2D)  (None, 1024, 1024, 4 0           add_149[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_445 (ReLU)                (None, 1024, 1024, 4 0           symmetrize2d_72[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, None, None, 2 10368       re_lu_445[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_434 (BatchN (None, None, None, 2 96          conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_446 (ReLU)                (None, None, None, 2 0           batch_normalization_434[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, None, None, 4 1152        re_lu_446[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_435 (BatchN (None, None, None, 4 192         conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_150 (Dropout)           (None, None, None, 4 0           batch_normalization_435[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_150 (Add)                   (None, 1024, 1024, 4 0           symmetrize2d_72[0][0]            \n",
      "                                                                 dropout_150[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_73 (Symmetrize2D)  (None, 1024, 1024, 4 0           add_150[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_447 (ReLU)                (None, 1024, 1024, 4 0           symmetrize2d_73[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, None, None, 2 10368       re_lu_447[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_436 (BatchN (None, None, None, 2 96          conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_448 (ReLU)                (None, None, None, 2 0           batch_normalization_436[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, None, None, 4 1152        re_lu_448[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_437 (BatchN (None, None, None, 4 192         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_151 (Dropout)           (None, None, None, 4 0           batch_normalization_437[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_151 (Add)                   (None, 1024, 1024, 4 0           symmetrize2d_73[0][0]            \n",
      "                                                                 dropout_151[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_74 (Symmetrize2D)  (None, 1024, 1024, 4 0           add_151[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_449 (ReLU)                (None, 1024, 1024, 4 0           symmetrize2d_74[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, None, None, 2 10368       re_lu_449[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_438 (BatchN (None, None, None, 2 96          conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_450 (ReLU)                (None, None, None, 2 0           batch_normalization_438[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, None, None, 4 1152        re_lu_450[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_439 (BatchN (None, None, None, 4 192         conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_152 (Dropout)           (None, None, None, 4 0           batch_normalization_439[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_152 (Add)                   (None, 1024, 1024, 4 0           symmetrize2d_74[0][0]            \n",
      "                                                                 dropout_152[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_75 (Symmetrize2D)  (None, 1024, 1024, 4 0           add_152[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_451 (ReLU)                (None, 1024, 1024, 4 0           symmetrize2d_75[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, None, None, 2 10368       re_lu_451[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_440 (BatchN (None, None, None, 2 96          conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_452 (ReLU)                (None, None, None, 2 0           batch_normalization_440[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, None, None, 4 1152        re_lu_452[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_441 (BatchN (None, None, None, 4 192         conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_153 (Dropout)           (None, None, None, 4 0           batch_normalization_441[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_153 (Add)                   (None, 1024, 1024, 4 0           symmetrize2d_75[0][0]            \n",
      "                                                                 dropout_153[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_76 (Symmetrize2D)  (None, 1024, 1024, 4 0           add_153[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_3 (Cropping2D)       (None, 972, 972, 48) 0           symmetrize2d_76[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "upper_tri_10 (UpperTri)         (None, 470935, 48)   0           cropping2d_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 470935, 5)    245         upper_tri_10[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 705,189\n",
      "Trainable params: 699,877\n",
      "Non-trainable params: 5,312\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_sgd = tf.keras.optimizers.SGD(\n",
    "          lr=0.0065,\n",
    "          momentum=0.99575,\n",
    "          clipnorm=10.7)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.MSE,\n",
    "                    optimizer=optimizer_sgd,\n",
    "                    metrics=['mae']) # TODO: R^2 and Person custom metrics (? TensorBoard and EarlyStopping ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected sequence to have shape (1048576, 4) but got array with shape (524288, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-283-6404fa7316b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2649\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2651\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    383\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    386\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected sequence to have shape (1048576, 4) but got array with shape (524288, 4)"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x,\n",
    "                    train_y,\n",
    "                    batch_size=2,\n",
    "                    epochs=5,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, we implement NN without stochastic shift and hi-c matrix flip\n",
    "# this will help performance and is TODO\n",
    "# Also Fudenberg trains on 5 datasets at the same time (Multi-task training). This improves accuracy on all dataset predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Убрать crop, уменьшить НС, multitask learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# Fine-tuning method\n",
    "##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "# у его one-hot-encoding - ACGT Порядок сделать у меня такой же (поменять training set)\n",
    "# change training set to 512x512\n",
    "\n",
    "\n",
    "import json\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1' ### run on CPU\n",
    "print(tf.__version__)\n",
    "if tf.__version__[0] == '1':\n",
    "    tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "from cooltools.lib.numutils import set_diag\n",
    "from basenji import dataset, dna_io, seqnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sequence (InputLayer)           [(None, 1048576, 4)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stochastic_reverse_complement ( ((None, 1048576, 4), 0           sequence[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stochastic_shift (StochasticShi (None, 1048576, 4)   0           stochastic_reverse_complement[0][\n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 1048576, 4)   0           stochastic_shift[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 1048576, 96)  4224        re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1048576, 96)  384         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 524288, 96)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 524288, 96)   0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 524288, 96)   46080       re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 524288, 96)   384         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 262144, 96)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 262144, 96)   0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 262144, 96)   46080       re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 262144, 96)   384         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 131072, 96)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 131072, 96)   0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 131072, 96)   46080       re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 131072, 96)   384         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 65536, 96)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 65536, 96)    0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 65536, 96)    46080       re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 65536, 96)    384         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 32768, 96)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 32768, 96)    0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 32768, 96)    46080       re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32768, 96)    384         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 16384, 96)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 16384, 96)    0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 16384, 96)    46080       re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16384, 96)    384         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 8192, 96)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 8192, 96)     0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 8192, 96)     46080       re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8192, 96)     384         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 4096, 96)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 4096, 96)     0           max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 4096, 96)     46080       re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4096, 96)     384         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 2048, 96)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 2048, 96)     0           max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 2048, 96)     46080       re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 2048, 96)     384         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 1024, 96)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 1024, 96)     0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1024, 96)     46080       re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1024, 96)     384         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 512, 96)      0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 512, 96)      0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 512, 48)      13824       re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 512, 48)      192         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 512, 48)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 512, 96)      4608        re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 512, 96)      384         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512, 96)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 512, 96)      0           max_pooling1d_10[0][0]           \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 512, 96)      0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, None, 48)     13824       re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, 48)     192         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, None, 48)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, None, 96)     4608        re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, 96)     384         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 96)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 512, 96)      0           add[0][0]                        \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 512, 96)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, None, 48)     13824       re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, 48)     192         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, None, 48)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, None, 96)     4608        re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, 96)     384         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, None, 96)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 512, 96)      0           add_1[0][0]                      \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 512, 96)      0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, None, 48)     13824       re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, 48)     192         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, None, 48)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, None, 96)     4608        re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, 96)     384         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, None, 96)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 512, 96)      0           add_2[0][0]                      \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 512, 96)      0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, None, 48)     13824       re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, 48)     192         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, None, 48)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, None, 96)     4608        re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, 96)     384         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, None, 96)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 512, 96)      0           add_3[0][0]                      \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_21 (ReLU)                 (None, 512, 96)      0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, None, 48)     13824       re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, 48)     192         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_22 (ReLU)                 (None, None, 48)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, None, 96)     4608        re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, 96)     384         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, None, 96)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 512, 96)      0           add_4[0][0]                      \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_23 (ReLU)                 (None, 512, 96)      0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, None, 48)     13824       re_lu_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, 48)     192         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_24 (ReLU)                 (None, None, 48)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, None, 96)     4608        re_lu_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, 96)     384         conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, None, 96)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 512, 96)      0           add_5[0][0]                      \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_25 (ReLU)                 (None, 512, 96)      0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, None, 48)     13824       re_lu_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, 48)     192         conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_26 (ReLU)                 (None, None, 48)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, None, 96)     4608        re_lu_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, 96)     384         conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, None, 96)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 512, 96)      0           add_6[0][0]                      \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_27 (ReLU)                 (None, 512, 96)      0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 512, 64)      30720       re_lu_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 512, 64)      256         conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_28 (ReLU)                 (None, 512, 64)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_to2d (AverageTo2D)      (None, 512, 512, 64) 0           re_lu_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat_dist2d (ConcatDist2D)    (None, 512, 512, 65) 0           average_to2d[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_29 (ReLU)                 (None, 512, 512, 65) 0           concat_dist2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 512, 512, 48) 28080       re_lu_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 512, 512, 48) 192         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d (Symmetrize2D)     (None, 512, 512, 48) 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_30 (ReLU)                 (None, 512, 512, 48) 0           symmetrize2d[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 24) 10368       re_lu_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 512, 512, 24) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_31 (ReLU)                 (None, 512, 512, 24) 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 512, 512, 48) 1152        re_lu_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 512, 512, 48) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 512, 512, 48) 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 512, 512, 48) 0           symmetrize2d[0][0]               \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_1 (Symmetrize2D)   (None, 512, 512, 48) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_32 (ReLU)                 (None, 512, 512, 48) 0           symmetrize2d_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 2 10368       re_lu_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 2 96          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_33 (ReLU)                 (None, None, None, 2 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 4 1152        re_lu_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 4 192         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, None, None, 4 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 512, 512, 48) 0           symmetrize2d_1[0][0]             \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_2 (Symmetrize2D)   (None, 512, 512, 48) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_34 (ReLU)                 (None, 512, 512, 48) 0           symmetrize2d_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 2 10368       re_lu_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 2 96          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_35 (ReLU)                 (None, None, None, 2 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 4 1152        re_lu_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 4 192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, None, None, 4 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 512, 512, 48) 0           symmetrize2d_2[0][0]             \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_3 (Symmetrize2D)   (None, 512, 512, 48) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_36 (ReLU)                 (None, 512, 512, 48) 0           symmetrize2d_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 2 10368       re_lu_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 2 96          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_37 (ReLU)                 (None, None, None, 2 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 4 1152        re_lu_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 4 192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, None, None, 4 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 512, 512, 48) 0           symmetrize2d_3[0][0]             \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_4 (Symmetrize2D)   (None, 512, 512, 48) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_38 (ReLU)                 (None, 512, 512, 48) 0           symmetrize2d_4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 2 10368       re_lu_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 2 96          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_39 (ReLU)                 (None, None, None, 2 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 4 1152        re_lu_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 4 192         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, None, None, 4 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 512, 512, 48) 0           symmetrize2d_4[0][0]             \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_5 (Symmetrize2D)   (None, 512, 512, 48) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_40 (ReLU)                 (None, 512, 512, 48) 0           symmetrize2d_5[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 2 10368       re_lu_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 2 96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_41 (ReLU)                 (None, None, None, 2 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 4 1152        re_lu_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 4 192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, None, None, 4 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 512, 512, 48) 0           symmetrize2d_5[0][0]             \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_6 (Symmetrize2D)   (None, 512, 512, 48) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d (Cropping2D)         (None, 448, 448, 48) 0           symmetrize2d_6[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "upper_tri (UpperTri)            (None, 99681, 48)    0           cropping2d[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 99681, 5)     245         upper_tri[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "switch_reverse_triu (SwitchReve (None, 99681, 5)     0           dense[0][0]                      \n",
      "                                                                 stochastic_reverse_complement[0][\n",
      "==================================================================================================\n",
      "Total params: 751,653\n",
      "Trainable params: 746,149\n",
      "Non-trainable params: 5,504\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "model_strides [2048]\n",
      "target_lengths [99681]\n",
      "target_crops [-49585]\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"./basenji/\"\n",
    "params_file = model_dir+'params.json'\n",
    "model_file  = model_dir+'model_best.h5'\n",
    "with open(params_file) as params_open:\n",
    "    params = json.load(params_open)\n",
    "    params_model = params['model']\n",
    "    params_train = params['train']\n",
    "\n",
    "seq_length = params_model['seq_length']\n",
    "target_length = params_model['target_length']\n",
    "target_crop = params_model['target_crop']\n",
    "human_model = seqnn.SeqNN(params_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded\n"
     ]
    }
   ],
   "source": [
    "human_model.restore(model_file)\n",
    "print('successfully loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_model = human_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sequence (InputLayer)           [(None, 1048576, 4)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stochastic_reverse_complement ( ((None, 1048576, 4), 0           sequence[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stochastic_shift (StochasticShi (None, 1048576, 4)   0           stochastic_reverse_complement[0][\n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 1048576, 4)   0           stochastic_shift[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 1048576, 96)  4224        re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1048576, 96)  384         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 524288, 96)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 524288, 96)   0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 524288, 96)   46080       re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 524288, 96)   384         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 262144, 96)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 262144, 96)   0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 262144, 96)   46080       re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 262144, 96)   384         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 131072, 96)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 131072, 96)   0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 131072, 96)   46080       re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 131072, 96)   384         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 65536, 96)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 65536, 96)    0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 65536, 96)    46080       re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 65536, 96)    384         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 32768, 96)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 32768, 96)    0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 32768, 96)    46080       re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32768, 96)    384         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 16384, 96)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 16384, 96)    0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 16384, 96)    46080       re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16384, 96)    384         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 8192, 96)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 8192, 96)     0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 8192, 96)     46080       re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8192, 96)     384         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 4096, 96)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 4096, 96)     0           max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 4096, 96)     46080       re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4096, 96)     384         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 2048, 96)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 2048, 96)     0           max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 2048, 96)     46080       re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 2048, 96)     384         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 1024, 96)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 1024, 96)     0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1024, 96)     46080       re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1024, 96)     384         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 512, 96)      0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 512, 96)      0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 512, 48)      13824       re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 512, 48)      192         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 512, 48)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 512, 96)      4608        re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 512, 96)      384         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512, 96)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 512, 96)      0           max_pooling1d_10[0][0]           \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 512, 96)      0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, None, 48)     13824       re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, 48)     192         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, None, 48)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, None, 96)     4608        re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, 96)     384         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, None, 96)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 512, 96)      0           add[0][0]                        \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 512, 96)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, None, 48)     13824       re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, 48)     192         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, None, 48)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, None, 96)     4608        re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, 96)     384         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, None, 96)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 512, 96)      0           add_1[0][0]                      \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 512, 96)      0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, None, 48)     13824       re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, 48)     192         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, None, 48)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, None, 96)     4608        re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, None, 96)     384         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, None, 96)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 512, 96)      0           add_2[0][0]                      \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 512, 96)      0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, None, 48)     13824       re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, 48)     192         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, None, 48)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, None, 96)     4608        re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, 96)     384         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, None, 96)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 512, 96)      0           add_3[0][0]                      \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_21 (ReLU)                 (None, 512, 96)      0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, None, 48)     13824       re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, 48)     192         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_22 (ReLU)                 (None, None, 48)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, None, 96)     4608        re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, 96)     384         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, None, 96)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 512, 96)      0           add_4[0][0]                      \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_23 (ReLU)                 (None, 512, 96)      0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, None, 48)     13824       re_lu_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, 48)     192         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_24 (ReLU)                 (None, None, 48)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, None, 96)     4608        re_lu_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, 96)     384         conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, None, 96)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 512, 96)      0           add_5[0][0]                      \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_25 (ReLU)                 (None, 512, 96)      0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, None, 48)     13824       re_lu_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, None, 48)     192         conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_26 (ReLU)                 (None, None, 48)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, None, 96)     4608        re_lu_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, None, 96)     384         conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, None, 96)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 512, 96)      0           add_6[0][0]                      \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_27 (ReLU)                 (None, 512, 96)      0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 512, 64)      30720       re_lu_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 512, 64)      256         conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_28 (ReLU)                 (None, 512, 64)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_to2d (AverageTo2D)      (None, 512, 512, 64) 0           re_lu_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat_dist2d (ConcatDist2D)    (None, 512, 512, 65) 0           average_to2d[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_29 (ReLU)                 (None, 512, 512, 65) 0           concat_dist2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 512, 512, 48) 28080       re_lu_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 512, 512, 48) 192         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d (Symmetrize2D)     (None, 512, 512, 48) 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_30 (ReLU)                 (None, 512, 512, 48) 0           symmetrize2d[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 24) 10368       re_lu_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 512, 512, 24) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_31 (ReLU)                 (None, 512, 512, 24) 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 512, 512, 48) 1152        re_lu_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 512, 512, 48) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 512, 512, 48) 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 512, 512, 48) 0           symmetrize2d[0][0]               \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_1 (Symmetrize2D)   (None, 512, 512, 48) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_32 (ReLU)                 (None, 512, 512, 48) 0           symmetrize2d_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, None, None, 2 10368       re_lu_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, None, None, 2 96          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_33 (ReLU)                 (None, None, None, 2 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, None, None, 4 1152        re_lu_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, None, None, 4 192         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, None, None, 4 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 512, 512, 48) 0           symmetrize2d_1[0][0]             \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_2 (Symmetrize2D)   (None, 512, 512, 48) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_34 (ReLU)                 (None, 512, 512, 48) 0           symmetrize2d_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, None, None, 2 10368       re_lu_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, None, None, 2 96          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_35 (ReLU)                 (None, None, None, 2 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, None, None, 4 1152        re_lu_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, None, None, 4 192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, None, None, 4 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 512, 512, 48) 0           symmetrize2d_2[0][0]             \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_3 (Symmetrize2D)   (None, 512, 512, 48) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_36 (ReLU)                 (None, 512, 512, 48) 0           symmetrize2d_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, None, None, 2 10368       re_lu_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, None, None, 2 96          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_37 (ReLU)                 (None, None, None, 2 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, None, None, 4 1152        re_lu_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 4 192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, None, None, 4 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 512, 512, 48) 0           symmetrize2d_3[0][0]             \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_4 (Symmetrize2D)   (None, 512, 512, 48) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_38 (ReLU)                 (None, 512, 512, 48) 0           symmetrize2d_4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 2 10368       re_lu_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 2 96          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_39 (ReLU)                 (None, None, None, 2 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 4 1152        re_lu_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 4 192         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, None, None, 4 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 512, 512, 48) 0           symmetrize2d_4[0][0]             \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_5 (Symmetrize2D)   (None, 512, 512, 48) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_40 (ReLU)                 (None, 512, 512, 48) 0           symmetrize2d_5[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 2 10368       re_lu_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 2 96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_41 (ReLU)                 (None, None, None, 2 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 4 1152        re_lu_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 4 192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, None, None, 4 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 512, 512, 48) 0           symmetrize2d_5[0][0]             \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_6 (Symmetrize2D)   (None, 512, 512, 48) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d (Cropping2D)         (None, 448, 448, 48) 0           symmetrize2d_6[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "upper_tri (UpperTri)            (None, 99681, 48)    0           cropping2d[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 99681, 5)     245         upper_tri[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "switch_reverse_triu (SwitchReve (None, 99681, 5)     0           dense[0][0]                      \n",
      "                                                                 stochastic_reverse_complement[0][\n",
      "==================================================================================================\n",
      "Total params: 751,653\n",
      "Trainable params: 746,149\n",
      "Non-trainable params: 5,504\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "human_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.convolutional.Conv1D at 0x1a3a001780>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only relevant if model was compile 1 time\n",
    "human_model.get_layer(\"conv1d_2\") # layer from which we start copying weights\n",
    "human_model.get_layer(\"batch_normalization_40\") # layer at which we stop copying weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_model_layers = []\n",
    "for layer in human_model.layers[12:-7]:\n",
    "    if 'conv1d' in layer.name or 'batch_normalization' in layer.name or 'conv2d' in layer.name:\n",
    "        human_model_layers.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 524288\n",
    "sequence = tf.keras.Input(shape=(SEQ_LENGTH, 4), name='sequence')\n",
    "\n",
    "current = sequence\n",
    "\n",
    "# Augmentation - Enable it later (after good performance on the training set)\n",
    "# current, reverse_bool = StochasticReverseComplement()(current)\n",
    "# augment_shift = 11\n",
    "# current = StochasticShift(augment_shift)(current)\n",
    "\n",
    "# First 1D convolution\n",
    "current = conv_block(current, filters=96, kernel_size=11, pool_size=2, batch_norm=True, bn_momentum=0.9265,\n",
    "                     activation=\"relu\")\n",
    "\n",
    "# Multiple (11) 1D convolutions in a tower to arrive to 1024bp representation in 1D vectors\n",
    "current = conv_tower(current, filters_init=96, filters_mult=1.0, kernel_size=5, pool_size=2, repeat=9, \n",
    "                     batch_norm=True, bn_momentum=0.9265, activation=\"relu\")\n",
    "\n",
    "# Dilated residual layers\n",
    "current = dilated_residual(current, filters=48, rate_mult=1.75, repeat=8, dropout=0.4, batch_norm=True, \n",
    "                           bn_momentum=0.9265, activation=\"relu\")\n",
    "\n",
    "# Bottleneck 1D convolution\n",
    "current = conv_block(current, filters=64, kernel_size=5, batch_norm=True, bn_momentum=0.9265,\n",
    "                     activation=\"relu\")\n",
    "\n",
    "# final activation\n",
    "current = activate(current, \"relu\")\n",
    "\n",
    "\n",
    "# HEAD:\n",
    "current = one_to_two(current)\n",
    "current = concat_dist_2d(current)\n",
    "current = conv_block_2d(current, filters=48, kernel_size=3, batch_norm=True, bn_momentum=0.9265,\n",
    "                     activation=\"relu\")\n",
    "\n",
    "current = symmetrize_2d(current)\n",
    "current = dilated_residual_2d(current, filters=24, kernel_size=3, rate_mult=1.75, repeat=6, dropout=0.1,\n",
    "                              batch_norm=True, bn_momentum=0.9265, activation=\"relu\")\n",
    "\n",
    "# TODO: TRY WITHOUT CROP\n",
    "# current = cropping_2d(current, cropping=26)\n",
    "\n",
    "current = upper_tri(current, diagonal_offset=2)\n",
    "\n",
    "current = dense(current, units=1, activation=\"linear\")\n",
    "# current = dense(current, units=5, activation=\"linear\")\n",
    "\n",
    "# current = SwitchReverse()([current, reverse_bool])\n",
    "\n",
    "# make model\n",
    "drosophila_model = tf.keras.Model(inputs=sequence, outputs=current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sequence (InputLayer)           [(None, 524288, 4)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_453 (ReLU)                (None, 524288, 4)    0           sequence[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_299 (Conv1D)             (None, 524288, 96)   4224        re_lu_453[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_442 (BatchN (None, 524288, 96)   384         conv1d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_112 (MaxPooling1D (None, 262144, 96)   0           batch_normalization_442[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_454 (ReLU)                (None, 262144, 96)   0           max_pooling1d_112[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_300 (Conv1D)             (None, 262144, 96)   46080       re_lu_454[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_443 (BatchN (None, 262144, 96)   384         conv1d_300[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_113 (MaxPooling1D (None, 131072, 96)   0           batch_normalization_443[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_455 (ReLU)                (None, 131072, 96)   0           max_pooling1d_113[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_301 (Conv1D)             (None, 131072, 96)   46080       re_lu_455[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_444 (BatchN (None, 131072, 96)   384         conv1d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_114 (MaxPooling1D (None, 65536, 96)    0           batch_normalization_444[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_456 (ReLU)                (None, 65536, 96)    0           max_pooling1d_114[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_302 (Conv1D)             (None, 65536, 96)    46080       re_lu_456[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_445 (BatchN (None, 65536, 96)    384         conv1d_302[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_115 (MaxPooling1D (None, 32768, 96)    0           batch_normalization_445[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_457 (ReLU)                (None, 32768, 96)    0           max_pooling1d_115[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_303 (Conv1D)             (None, 32768, 96)    46080       re_lu_457[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_446 (BatchN (None, 32768, 96)    384         conv1d_303[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_116 (MaxPooling1D (None, 16384, 96)    0           batch_normalization_446[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_458 (ReLU)                (None, 16384, 96)    0           max_pooling1d_116[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_304 (Conv1D)             (None, 16384, 96)    46080       re_lu_458[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_447 (BatchN (None, 16384, 96)    384         conv1d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_117 (MaxPooling1D (None, 8192, 96)     0           batch_normalization_447[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_459 (ReLU)                (None, 8192, 96)     0           max_pooling1d_117[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_305 (Conv1D)             (None, 8192, 96)     46080       re_lu_459[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_448 (BatchN (None, 8192, 96)     384         conv1d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_118 (MaxPooling1D (None, 4096, 96)     0           batch_normalization_448[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_460 (ReLU)                (None, 4096, 96)     0           max_pooling1d_118[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_306 (Conv1D)             (None, 4096, 96)     46080       re_lu_460[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_449 (BatchN (None, 4096, 96)     384         conv1d_306[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_119 (MaxPooling1D (None, 2048, 96)     0           batch_normalization_449[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_461 (ReLU)                (None, 2048, 96)     0           max_pooling1d_119[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_307 (Conv1D)             (None, 2048, 96)     46080       re_lu_461[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_450 (BatchN (None, 2048, 96)     384         conv1d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_120 (MaxPooling1D (None, 1024, 96)     0           batch_normalization_450[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_462 (ReLU)                (None, 1024, 96)     0           max_pooling1d_120[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_308 (Conv1D)             (None, 1024, 96)     46080       re_lu_462[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_451 (BatchN (None, 1024, 96)     384         conv1d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_121 (MaxPooling1D (None, 512, 96)      0           batch_normalization_451[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_463 (ReLU)                (None, 512, 96)      0           max_pooling1d_121[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_309 (Conv1D)             (None, 512, 48)      13824       re_lu_463[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_452 (BatchN (None, 512, 48)      192         conv1d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_464 (ReLU)                (None, 512, 48)      0           batch_normalization_452[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_310 (Conv1D)             (None, 512, 96)      4608        re_lu_464[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_453 (BatchN (None, 512, 96)      384         conv1d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_154 (Dropout)           (None, 512, 96)      0           batch_normalization_453[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_154 (Add)                   (None, 512, 96)      0           max_pooling1d_121[0][0]          \n",
      "                                                                 dropout_154[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_465 (ReLU)                (None, 512, 96)      0           add_154[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_311 (Conv1D)             (None, None, 48)     13824       re_lu_465[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_454 (BatchN (None, None, 48)     192         conv1d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_466 (ReLU)                (None, None, 48)     0           batch_normalization_454[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_312 (Conv1D)             (None, None, 96)     4608        re_lu_466[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_455 (BatchN (None, None, 96)     384         conv1d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_155 (Dropout)           (None, None, 96)     0           batch_normalization_455[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_155 (Add)                   (None, 512, 96)      0           add_154[0][0]                    \n",
      "                                                                 dropout_155[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_467 (ReLU)                (None, 512, 96)      0           add_155[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_313 (Conv1D)             (None, None, 48)     13824       re_lu_467[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_456 (BatchN (None, None, 48)     192         conv1d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_468 (ReLU)                (None, None, 48)     0           batch_normalization_456[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_314 (Conv1D)             (None, None, 96)     4608        re_lu_468[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_457 (BatchN (None, None, 96)     384         conv1d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_156 (Dropout)           (None, None, 96)     0           batch_normalization_457[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_156 (Add)                   (None, 512, 96)      0           add_155[0][0]                    \n",
      "                                                                 dropout_156[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_469 (ReLU)                (None, 512, 96)      0           add_156[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_315 (Conv1D)             (None, None, 48)     13824       re_lu_469[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_458 (BatchN (None, None, 48)     192         conv1d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_470 (ReLU)                (None, None, 48)     0           batch_normalization_458[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_316 (Conv1D)             (None, None, 96)     4608        re_lu_470[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_459 (BatchN (None, None, 96)     384         conv1d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_157 (Dropout)           (None, None, 96)     0           batch_normalization_459[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_157 (Add)                   (None, 512, 96)      0           add_156[0][0]                    \n",
      "                                                                 dropout_157[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_471 (ReLU)                (None, 512, 96)      0           add_157[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_317 (Conv1D)             (None, None, 48)     13824       re_lu_471[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_460 (BatchN (None, None, 48)     192         conv1d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_472 (ReLU)                (None, None, 48)     0           batch_normalization_460[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_318 (Conv1D)             (None, None, 96)     4608        re_lu_472[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_461 (BatchN (None, None, 96)     384         conv1d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_158 (Dropout)           (None, None, 96)     0           batch_normalization_461[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_158 (Add)                   (None, 512, 96)      0           add_157[0][0]                    \n",
      "                                                                 dropout_158[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_473 (ReLU)                (None, 512, 96)      0           add_158[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_319 (Conv1D)             (None, None, 48)     13824       re_lu_473[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_462 (BatchN (None, None, 48)     192         conv1d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_474 (ReLU)                (None, None, 48)     0           batch_normalization_462[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_320 (Conv1D)             (None, None, 96)     4608        re_lu_474[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_463 (BatchN (None, None, 96)     384         conv1d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_159 (Dropout)           (None, None, 96)     0           batch_normalization_463[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_159 (Add)                   (None, 512, 96)      0           add_158[0][0]                    \n",
      "                                                                 dropout_159[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_475 (ReLU)                (None, 512, 96)      0           add_159[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_321 (Conv1D)             (None, None, 48)     13824       re_lu_475[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_464 (BatchN (None, None, 48)     192         conv1d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_476 (ReLU)                (None, None, 48)     0           batch_normalization_464[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_322 (Conv1D)             (None, None, 96)     4608        re_lu_476[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_465 (BatchN (None, None, 96)     384         conv1d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_160 (Dropout)           (None, None, 96)     0           batch_normalization_465[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_160 (Add)                   (None, 512, 96)      0           add_159[0][0]                    \n",
      "                                                                 dropout_160[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_477 (ReLU)                (None, 512, 96)      0           add_160[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_323 (Conv1D)             (None, None, 48)     13824       re_lu_477[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_466 (BatchN (None, None, 48)     192         conv1d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_478 (ReLU)                (None, None, 48)     0           batch_normalization_466[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_324 (Conv1D)             (None, None, 96)     4608        re_lu_478[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_467 (BatchN (None, None, 96)     384         conv1d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_161 (Dropout)           (None, None, 96)     0           batch_normalization_467[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_161 (Add)                   (None, 512, 96)      0           add_160[0][0]                    \n",
      "                                                                 dropout_161[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_479 (ReLU)                (None, 512, 96)      0           add_161[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_325 (Conv1D)             (None, 512, 64)      30720       re_lu_479[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_468 (BatchN (None, 512, 64)      256         conv1d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_480 (ReLU)                (None, 512, 64)      0           batch_normalization_468[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "one_to_two_10 (OneToTwo)        (None, 512, 512, 64) 0           re_lu_480[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concat_dist2d_11 (ConcatDist2D) (None, 512, 512, 65) 0           one_to_two_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_481 (ReLU)                (None, 512, 512, 65) 0           concat_dist2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 512, 512, 48) 28080       re_lu_481[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_469 (BatchN (None, 512, 512, 48) 192         conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_77 (Symmetrize2D)  (None, 512, 512, 48) 0           batch_normalization_469[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_482 (ReLU)                (None, 512, 512, 48) 0           symmetrize2d_77[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 512, 512, 24) 10368       re_lu_482[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_470 (BatchN (None, 512, 512, 24) 96          conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_483 (ReLU)                (None, 512, 512, 24) 0           batch_normalization_470[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 512, 512, 48) 1152        re_lu_483[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_471 (BatchN (None, 512, 512, 48) 192         conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_162 (Dropout)           (None, 512, 512, 48) 0           batch_normalization_471[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_162 (Add)                   (None, 512, 512, 48) 0           symmetrize2d_77[0][0]            \n",
      "                                                                 dropout_162[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_78 (Symmetrize2D)  (None, 512, 512, 48) 0           add_162[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_484 (ReLU)                (None, 512, 512, 48) 0           symmetrize2d_78[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, None, None, 2 10368       re_lu_484[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_472 (BatchN (None, None, None, 2 96          conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_485 (ReLU)                (None, None, None, 2 0           batch_normalization_472[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, None, None, 4 1152        re_lu_485[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_473 (BatchN (None, None, None, 4 192         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_163 (Dropout)           (None, None, None, 4 0           batch_normalization_473[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_163 (Add)                   (None, 512, 512, 48) 0           symmetrize2d_78[0][0]            \n",
      "                                                                 dropout_163[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_79 (Symmetrize2D)  (None, 512, 512, 48) 0           add_163[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_486 (ReLU)                (None, 512, 512, 48) 0           symmetrize2d_79[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, None, None, 2 10368       re_lu_486[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_474 (BatchN (None, None, None, 2 96          conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_487 (ReLU)                (None, None, None, 2 0           batch_normalization_474[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, None, None, 4 1152        re_lu_487[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_475 (BatchN (None, None, None, 4 192         conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_164 (Dropout)           (None, None, None, 4 0           batch_normalization_475[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_164 (Add)                   (None, 512, 512, 48) 0           symmetrize2d_79[0][0]            \n",
      "                                                                 dropout_164[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_80 (Symmetrize2D)  (None, 512, 512, 48) 0           add_164[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_488 (ReLU)                (None, 512, 512, 48) 0           symmetrize2d_80[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, None, None, 2 10368       re_lu_488[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_476 (BatchN (None, None, None, 2 96          conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_489 (ReLU)                (None, None, None, 2 0           batch_normalization_476[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, None, None, 4 1152        re_lu_489[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_477 (BatchN (None, None, None, 4 192         conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_165 (Dropout)           (None, None, None, 4 0           batch_normalization_477[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_165 (Add)                   (None, 512, 512, 48) 0           symmetrize2d_80[0][0]            \n",
      "                                                                 dropout_165[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_81 (Symmetrize2D)  (None, 512, 512, 48) 0           add_165[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_490 (ReLU)                (None, 512, 512, 48) 0           symmetrize2d_81[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, None, None, 2 10368       re_lu_490[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_478 (BatchN (None, None, None, 2 96          conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_491 (ReLU)                (None, None, None, 2 0           batch_normalization_478[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, None, None, 4 1152        re_lu_491[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_479 (BatchN (None, None, None, 4 192         conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_166 (Dropout)           (None, None, None, 4 0           batch_normalization_479[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_166 (Add)                   (None, 512, 512, 48) 0           symmetrize2d_81[0][0]            \n",
      "                                                                 dropout_166[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_82 (Symmetrize2D)  (None, 512, 512, 48) 0           add_166[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_492 (ReLU)                (None, 512, 512, 48) 0           symmetrize2d_82[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, None, None, 2 10368       re_lu_492[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_480 (BatchN (None, None, None, 2 96          conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_493 (ReLU)                (None, None, None, 2 0           batch_normalization_480[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, None, None, 4 1152        re_lu_493[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_481 (BatchN (None, None, None, 4 192         conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_167 (Dropout)           (None, None, None, 4 0           batch_normalization_481[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_167 (Add)                   (None, 512, 512, 48) 0           symmetrize2d_82[0][0]            \n",
      "                                                                 dropout_167[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_83 (Symmetrize2D)  (None, 512, 512, 48) 0           add_167[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "upper_tri_11 (UpperTri)         (None, 130305, 48)   0           symmetrize2d_83[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 130305, 1)    49          upper_tri_11[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 704,993\n",
      "Trainable params: 699,681\n",
      "Non-trainable params: 5,312\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "drosophila_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_sgd = tf.keras.optimizers.SGD(\n",
    "          lr=0.0065,\n",
    "          momentum=0.99575,\n",
    "          clipnorm=10.7)\n",
    "\n",
    "drosophila_model.compile(loss=tf.keras.losses.MSE,\n",
    "                    optimizer=optimizer_sgd,\n",
    "                    metrics=['mae']) # TODO: R^2 and Person custom metrics (? TensorBoard and EarlyStopping ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2638\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2639\u001b[0;31m         \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2640\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'batch_normalization_459/cond_1' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m       \u001b[0mxla_compile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaCompile\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m       xla_separate_compiled_gradients = op.get_attr(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2642\u001b[0m       \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2643\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2644\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operation 'batch_normalization_459/cond_1' has no attr named '_XlaCompile'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-286-b3c6778ae449>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m   \u001b[0;31m# Get step function and loop type.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m   \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_execution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m   \u001b[0muse_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_dataset\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m   \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_inputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36m_make_execution_function\u001b[0;34m(model, mode)\u001b[0m\n\u001b[1;32m    530\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistributed_training_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_execution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_execution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_execution_function\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   2274\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_make_execution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2276\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2277\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2278\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2217\u001b[0m           \u001b[0;31m# Training updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2218\u001b[0m           updates = self.optimizer.get_updates(\n\u001b[0;32m-> 2219\u001b[0;31m               params=self._collected_trainable_weights, loss=self.total_loss)\n\u001b[0m\u001b[1;32m   2220\u001b[0m       \u001b[0;31m# Unconditional updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2221\u001b[0m       \u001b[0mupdates\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_updates_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m     self._assert_valid_dtypes([\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mget_gradients\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scope_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m       \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         unconnected_gradients)\n\u001b[0m\u001b[1;32m    159\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 731\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    732\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_MaybeCompile\u001b[0;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[1;32m    401\u001b[0m       \u001b[0mxla_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_XlaScope\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Exit early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mxla_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0;31m# functions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                 in_grads = _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m--> 731\u001b[0;31m                                          lambda: grad_fn(op, *out_grads))\n\u001b[0m\u001b[1;32m    732\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# For function call ops, we add a 'SymbolicGradient'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m_IfGrad\u001b[0;34m(op, *grads)\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;31m# Get the if operator (this logic handles the case where op is a MockOp)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mif_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0mtrue_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_func_graphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mif_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m   \u001b[0;31m# Note: op.graph != ops.get_default_graph() when we are computing the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;31m# of a nested cond.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m_get_func_graphs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"If\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     return (_get_func_graph_for_branch(op.get_attr(\"then_branch\")),\n\u001b[0;32m--> 265\u001b[0;31m             _get_func_graph_for_branch(op.get_attr(\"else_branch\")))\n\u001b[0m\u001b[1;32m    266\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Case\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     return [_get_func_graph_for_branch(branch_fn)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/cond_v2.py\u001b[0m in \u001b[0;36m_get_func_graph_for_branch\u001b[0;34m(name_attr_list)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m       func_graph = function_def_to_graph.function_def_to_graph(\n\u001b[0;32m--> 256\u001b[0;31m           fdef, input_shapes)\n\u001b[0m\u001b[1;32m    257\u001b[0m     func_graph.captures = collections.OrderedDict(zip(inputs,\n\u001b[1;32m    258\u001b[0m                                                       func_graph.inputs))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/function_def_to_graph.py\u001b[0m in \u001b[0;36mfunction_def_to_graph\u001b[0;34m(fdef, input_shapes)\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# Add all function nodes to the graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mimporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# Initialize fields specific to FuncGraph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/importer.py\u001b[0m in \u001b[0;36mimport_graph_def\u001b[0;34m(graph_def, input_map, return_elements, name, op_dict, producer_op_list)\u001b[0m\n\u001b[1;32m    425\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         results = c_api.TF_GraphImportGraphDefWithResults(\n\u001b[0;32m--> 427\u001b[0;31m             graph._c_graph, serialized, options)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScopedTFImportGraphDefResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "drosophila_model.fit(train_x,\n",
    "                    train_y,\n",
    "                    batch_size=2,\n",
    "                    epochs=5,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(731, 524288, 4)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(731, 130305, 1)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "524.288"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "524288 / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "856.0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(526000 - 524288) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "526 - 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Алгоритм\n",
    "# Берем последовательности ДНК 526.000. В нейронке (или в процессе формирования трен множества) клипаем их с двух сторон по 856 с каждой -> 524288\n",
    "# Берем Hi-C 526x526 -> клипаем по 7 c каждой стороны -> 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set weights from the fudenberg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for layer in drosophila_model.layers[6:]:\n",
    "    if 'conv1d' in layer.name or 'batch_normalization' in layer.name or 'conv2d' in layer.name:\n",
    "        layer.set_weights(human_model_layers[count].get_weights())\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Transfer learning method\n",
    "################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
